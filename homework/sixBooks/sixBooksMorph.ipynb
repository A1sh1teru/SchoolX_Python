{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-sm==3.7.0) (1.2.1)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: docopt-ng>=0.6 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.7.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (57.4.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\velic\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\velic\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl (513.4 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-lg==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-lg==3.7.0) (1.2.1)\n",
      "Requirement already satisfied: docopt-ng>=0.6 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (0.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (57.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\velic\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.3.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\velic\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.1.3)\n",
      "Collecting ru-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl (513.4 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-lg==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-lg==3.7.0) (1.2.1)\n",
      "Requirement already satisfied: docopt-ng>=0.6 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (0.7.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (57.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\velic\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.3.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\velic\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\velic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q nltk\n",
    "%pip install -q pymorphy2\n",
    "%pip install -q spacy\n",
    "# %pip install -q spacy download ru_core_news_lg\n",
    "%pip install https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl\n",
    "%pip install https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./krestyanskie_deti1861.txt', 'r', encoding='utf-8') as file:\n",
    "    book1861 = file.read()\n",
    "\n",
    "with open('./moroz_krasnyy_nos_1864.txt', 'r', encoding='ansi') as file:\n",
    "    book1864 = file.read()\n",
    "\n",
    "with open('./zheleznaya_doroga_1865.txt', 'r', encoding='ansi') as file:\n",
    "    book1865 = file.read()\n",
    "\n",
    "with open('./dedushka_mazay_i_zaycy_1871.txt', 'r', encoding='ansi') as file:\n",
    "    book1871 = file.read()\n",
    "\n",
    "with open('./russkie_zhenshiny_1872.txt', 'r', encoding='utf-8') as file:\n",
    "    book1872 = file.read()\n",
    "\n",
    "with open('./komu_na_rusi_zhit_horosho_1874.txt', 'r', encoding='utf-8') as file:\n",
    "    book1874 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лексическое разнообразие произведения \"Крестьянские дети\":\n",
      "0.6877243359655419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество прилагательных в тексте: 749\n",
      "Количество уникальных прилагательных в тексте: 118\n",
      "Разнообразие прилагательных: 0.157543391188251\n"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(book1861):\n",
    "    words = re.findall(r'\\w+', book1861)\n",
    "    return words\n",
    "\n",
    "print('Лексическое разнообразие произведения \"Крестьянские дети\":')\n",
    "tokens = word_tokenizer(book1861)\n",
    "wordsCount = len(tokens)\n",
    "uniqueWords = list(set(tokens))\n",
    "uniqueWordsCount = len(uniqueWords)\n",
    "ttr1861 = uniqueWordsCount/wordsCount\n",
    "print(ttr1861)\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "tokens = word_tokenizer(book1861)\n",
    "\n",
    "countADJ1861 = 0\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            countADJ1861 += 1\n",
    "\n",
    "print(f'Количество прилагательных в тексте: {countADJ1861}')\n",
    "\n",
    "unique_adjectives = set()\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            unique_adjectives.add(parsed.normal_form)\n",
    "\n",
    "countUADJ1861 = len(unique_adjectives)\n",
    "print(f'Количество уникальных прилагательных в тексте: {countUADJ1861}')\n",
    "\n",
    "ttrADJ1861 = countUADJ1861/countADJ1861\n",
    "print('Разнообразие прилагательных:', ttrADJ1861)\n",
    "\n",
    "\n",
    "# nlp = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "# doc = nlp(book1861)\n",
    "\n",
    "# for sentence in doc.sents:\n",
    "#     print(\"Предложение:\", sentence.text)\n",
    "#     for token in sentence:\n",
    "#         print(\"Слово:\", token.text)\n",
    "#         print(\"Лемма:\", token.lemma_)\n",
    "#         print(\"Частеречный тег:\", token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лексическое разнообразие произведения \"Мороз, Красный нос\":\n",
      "0.5918367346938775\n",
      "Количество прилагательных в тексте: 2559\n",
      "Количество уникальных прилагательных в тексте: 251\n",
      "Разнообразие прилагательных: 0.09808518952715904\n"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(book1864):\n",
    "    words = re.findall(r'\\w+', book1864)\n",
    "    return words\n",
    "\n",
    "print('Лексическое разнообразие произведения \"Мороз, Красный нос\":')\n",
    "tokens = word_tokenizer(book1864)\n",
    "wordsCount = len(tokens)\n",
    "uniqueWords = list(set(tokens))\n",
    "uniqueWordsCount = len(uniqueWords)\n",
    "ttr1864 = uniqueWordsCount/wordsCount\n",
    "print(ttr1864)\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "tokens = word_tokenizer(book1864)\n",
    "\n",
    "countADJ1864 = 0\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            countADJ1864 += 1\n",
    "\n",
    "print(f'Количество прилагательных в тексте: {countADJ1864}')\n",
    "\n",
    "unique_adjectives = set()\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            unique_adjectives.add(parsed.normal_form)\n",
    "\n",
    "countUADJ1864 = len(unique_adjectives)\n",
    "print(f'Количество уникальных прилагательных в тексте: {countUADJ1864}')\n",
    "\n",
    "ttrADJ1864 = countUADJ1864/countADJ1864\n",
    "print('Разнообразие прилагательных:', ttrADJ1864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лексическое разнообразие произведения \"Железная дорога\":\n",
      "0.7598944591029023\n",
      "Количество прилагательных в тексте: 336\n",
      "Количество уникальных прилагательных в тексте: 79\n",
      "Разнообразие прилагательных: 0.23511904761904762\n"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(book1865):\n",
    "    words = re.findall(r'\\w+', book1865)\n",
    "    return words\n",
    "\n",
    "print('Лексическое разнообразие произведения \"Железная дорога\":')\n",
    "tokens = word_tokenizer(book1865)\n",
    "wordsCount = len(tokens)\n",
    "uniqueWords = list(set(tokens))\n",
    "uniqueWordsCount = len(uniqueWords)\n",
    "ttr1865 = uniqueWordsCount/wordsCount\n",
    "print(ttr1865)\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "tokens = word_tokenizer(book1865)\n",
    "\n",
    "countADJ1865 = 0\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            countADJ1865 += 1\n",
    "\n",
    "print(f'Количество прилагательных в тексте: {countADJ1865}')\n",
    "\n",
    "unique_adjectives = set()\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            unique_adjectives.add(parsed.normal_form)\n",
    "\n",
    "countUADJ1865 = len(unique_adjectives)\n",
    "print(f'Количество уникальных прилагательных в тексте: {countUADJ1865}')\n",
    "\n",
    "ttrADJ1865 = countUADJ1865/countADJ1865\n",
    "print('Разнообразие прилагательных:', ttrADJ1865)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лексическое разнообразие произведения \"Дедушка Мазай и зайцы\":\n",
      "0.7258485639686684\n",
      "Количество прилагательных в тексте: 639\n",
      "Количество уникальных прилагательных в тексте: 48\n",
      "Разнообразие прилагательных: 0.07511737089201878\n"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(book1871):\n",
    "    words = re.findall(r'\\w+', book1871)\n",
    "    return words\n",
    "\n",
    "print('Лексическое разнообразие произведения \"Дедушка Мазай и зайцы\":')\n",
    "tokens = word_tokenizer(book1871)\n",
    "wordsCount = len(tokens)\n",
    "uniqueWords = list(set(tokens))\n",
    "uniqueWordsCount = len(uniqueWords)\n",
    "ttr1871 = uniqueWordsCount/wordsCount\n",
    "print(ttr1871)\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "tokens = word_tokenizer(book1871)\n",
    "\n",
    "countADJ1871 = 0\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            countADJ1871 += 1\n",
    "\n",
    "print(f'Количество прилагательных в тексте: {countADJ1871}')\n",
    "\n",
    "unique_adjectives = set()\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            unique_adjectives.add(parsed.normal_form)\n",
    "\n",
    "countUADJ1871 = len(unique_adjectives)\n",
    "print(f'Количество уникальных прилагательных в тексте: {countUADJ1871}')\n",
    "\n",
    "ttrADJ1871 = countUADJ1871/countADJ1871\n",
    "print('Разнообразие прилагательных:', ttrADJ1871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лексическое разнообразие произведения \"Русские женщины\":\n",
      "0.45311400422237863\n",
      "Количество прилагательных в тексте: 6903\n",
      "Количество уникальных прилагательных в тексте: 451\n",
      "Разнообразие прилагательных: 0.06533391279153991\n"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(book1872):\n",
    "    words = re.findall(r'\\w+', book1872)\n",
    "    return words\n",
    "\n",
    "print('Лексическое разнообразие произведения \"Русские женщины\":')\n",
    "tokens = word_tokenizer(book1872)\n",
    "wordsCount = len(tokens)\n",
    "uniqueWords = list(set(tokens))\n",
    "uniqueWordsCount = len(uniqueWords)\n",
    "ttr1872 = uniqueWordsCount/wordsCount\n",
    "print(ttr1872)\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "tokens = word_tokenizer(book1872)\n",
    "\n",
    "countADJ1872 = 0\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            countADJ1872 += 1\n",
    "\n",
    "print(f'Количество прилагательных в тексте: {countADJ1872}')\n",
    "\n",
    "unique_adjectives = set()\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            unique_adjectives.add(parsed.normal_form)\n",
    "\n",
    "countUADJ1872 = len(unique_adjectives)\n",
    "print(f'Количество уникальных прилагательных в тексте: {countUADJ1872}')\n",
    "\n",
    "ttrADJ1872 = countUADJ1872/countADJ1872\n",
    "print('Разнообразие прилагательных:', ttrADJ1872)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лексическое разнообразие произведения \"Кому на Руси жить хорошо\":\n",
      "0.40199765706886986\n",
      "Количество прилагательных в тексте: 15403\n",
      "Количество уникальных прилагательных в тексте: 1120\n",
      "Разнообразие прилагательных: 0.07271310783613581\n"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(book1874):\n",
    "    words = re.findall(r'\\w+', book1874)\n",
    "    return words\n",
    "\n",
    "print('Лексическое разнообразие произведения \"Кому на Руси жить хорошо\":')\n",
    "tokens = word_tokenizer(book1874)\n",
    "wordsCount = len(tokens)\n",
    "uniqueWords = list(set(tokens))\n",
    "uniqueWordsCount = len(uniqueWords)\n",
    "ttr1874 = uniqueWordsCount/wordsCount\n",
    "print(ttr1874)\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "tokens = word_tokenizer(book1874)\n",
    "\n",
    "countADJ1874 = 0\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            countADJ1874 += 1\n",
    "\n",
    "print(f'Количество прилагательных в тексте: {countADJ1874}')\n",
    "\n",
    "unique_adjectives = set()\n",
    "for token in tokens:\n",
    "    parsed_word = morph.parse(token)\n",
    "    for parsed in parsed_word:\n",
    "        if \"ADJF\" in parsed.tag:\n",
    "            unique_adjectives.add(parsed.normal_form)\n",
    "\n",
    "countUADJ1874 = len(unique_adjectives)\n",
    "print(f'Количество уникальных прилагательных в тексте: {countUADJ1874}')\n",
    "\n",
    "ttrADJ1874 = countUADJ1874/countADJ1874\n",
    "print('Разнообразие прилагательных:', ttrADJ1874)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c31e3 th {\n",
       "  background-color: lightblue;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_c31e3_row0_col0, #T_c31e3_row0_col1, #T_c31e3_row0_col2, #T_c31e3_row1_col0, #T_c31e3_row1_col1, #T_c31e3_row1_col2, #T_c31e3_row2_col0, #T_c31e3_row2_col1, #T_c31e3_row2_col2, #T_c31e3_row3_col0, #T_c31e3_row3_col1, #T_c31e3_row3_col2, #T_c31e3_row4_col0, #T_c31e3_row4_col1, #T_c31e3_row4_col2, #T_c31e3_row5_col0, #T_c31e3_row5_col1, #T_c31e3_row5_col2 {\n",
       "  background-color: pink;\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c31e3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c31e3_level0_col0\" class=\"col_heading level0 col0\" >Text</th>\n",
       "      <th id=\"T_c31e3_level0_col1\" class=\"col_heading level0 col1\" >Разнообразие прилагательных</th>\n",
       "      <th id=\"T_c31e3_level0_col2\" class=\"col_heading level0 col2\" >Лексическое разнообразие слов</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c31e3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c31e3_row0_col0\" class=\"data row0 col0\" >book1861</td>\n",
       "      <td id=\"T_c31e3_row0_col1\" class=\"data row0 col1\" >0.157543</td>\n",
       "      <td id=\"T_c31e3_row0_col2\" class=\"data row0 col2\" >0.687724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31e3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c31e3_row1_col0\" class=\"data row1 col0\" >book1864</td>\n",
       "      <td id=\"T_c31e3_row1_col1\" class=\"data row1 col1\" >0.098085</td>\n",
       "      <td id=\"T_c31e3_row1_col2\" class=\"data row1 col2\" >0.591837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31e3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c31e3_row2_col0\" class=\"data row2 col0\" >book1865</td>\n",
       "      <td id=\"T_c31e3_row2_col1\" class=\"data row2 col1\" >0.235119</td>\n",
       "      <td id=\"T_c31e3_row2_col2\" class=\"data row2 col2\" >0.759894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31e3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c31e3_row3_col0\" class=\"data row3 col0\" >book1871</td>\n",
       "      <td id=\"T_c31e3_row3_col1\" class=\"data row3 col1\" >0.075117</td>\n",
       "      <td id=\"T_c31e3_row3_col2\" class=\"data row3 col2\" >0.725849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31e3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c31e3_row4_col0\" class=\"data row4 col0\" >book1872</td>\n",
       "      <td id=\"T_c31e3_row4_col1\" class=\"data row4 col1\" >0.065334</td>\n",
       "      <td id=\"T_c31e3_row4_col2\" class=\"data row4 col2\" >0.453114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31e3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c31e3_row5_col0\" class=\"data row5 col0\" >book1874</td>\n",
       "      <td id=\"T_c31e3_row5_col1\" class=\"data row5 col1\" >0.072713</td>\n",
       "      <td id=\"T_c31e3_row5_col2\" class=\"data row5 col2\" >0.401998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2342fdfca90>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Text': ['book1861', 'book1864', 'book1865', 'book1871', 'book1872', 'book1874'],\n",
    "    'Разнообразие прилагательных': [ttrADJ1861, ttrADJ1864, ttrADJ1865, ttrADJ1871, ttrADJ1872, ttrADJ1874],\n",
    "    'Лексическое разнообразие слов': [ttr1861, ttr1864, ttr1865, ttr1871, ttr1872, ttr1874]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def apply_styles_to_dataframe(dataframe):\n",
    "    return (\n",
    "        dataframe.style\n",
    "        .set_properties(**{'background-color': 'pink', 'color': 'black'})\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [('background-color', 'lightblue'), ('color', 'black'), ('font-weight', 'bold')]},\n",
    "        ])\n",
    "    )\n",
    "\n",
    "apply_styles_to_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые часто встречающиеся слова в тексте \"Крестьянкие дети\":\n",
      "поле (NOUN): 5\n",
      "большая (ADJ): 5\n",
      "было (AUX): 5\n",
      "мои (DET): 4\n",
      "щели (NOUN): 4\n",
      "\n",
      "Самые часто встречающиеся слова в тексте \"Мороз, Красный нос\":\n",
      "Но (CCONJ): 17\n",
      "бы (AUX): 14\n",
      "был (AUX): 9\n",
      "то (SCONJ): 9\n",
      "солнце (NOUN): 8\n",
      "\n",
      "Самые часто встречающиеся слова в тексте \"Железная дорога\":\n",
      "народ (NOUN): 6\n",
      "эту (DET): 5\n",
      "дорогу (NOUN): 4\n",
      "Всё (NOUN): 3\n",
      "этот (DET): 3\n",
      "\n",
      "Самые часто встречающиеся слова в тексте \"Дедушка Мазай и зайцы\":\n",
      "Мазай (PROPN): 8\n",
      "бы (AUX): 4\n",
      "Мазая (PROPN): 3\n",
      "мои (DET): 3\n",
      "Дедушка (NOUN): 2\n",
      "\n",
      "Самые часто встречающиеся слова в тексте \"Русские женщины\":\n",
      "Но (CCONJ): 72\n",
      "мой (DET): 34\n",
      "Княгиня (NOUN): 33\n",
      "был (AUX): 33\n",
      "было (AUX): 25\n",
      "его (PRON): 23\n",
      "была (AUX): 22\n",
      "то (SCONJ): 19\n",
      "Губернатор (NOUN): 19\n",
      "путь (NOUN): 18\n",
      "всJ (NOUN): 18\n",
      "нет (VERB): 17\n",
      "моя (DET): 17\n",
      "люди (NOUN): 17\n",
      "сказал (VERB): 15\n",
      "были (AUX): 15\n",
      "отец (NOUN): 14\n",
      "бы (AUX): 14\n",
      "сам (ADJ): 14\n",
      "Отец (NOUN): 14\n",
      "\n",
      "Самые часто встречающиеся слова в тексте \"Кому на Руси жить хорошо\":\n",
      "бы (AUX): 82\n",
      "нет (VERB): 60\n",
      "Бог (NOUN): 55\n",
      "странники (NOUN): 54\n",
      "то (SCONJ): 51\n",
      "Крестьяне (NOUN): 46\n",
      "сказал (VERB): 43\n",
      "Сказал (VERB): 43\n",
      "есть (VERB): 42\n",
      "был (AUX): 40\n",
      "сам (ADJ): 38\n",
      "ни (CCONJ): 36\n",
      "Ни (CCONJ): 36\n",
      "наши (DET): 35\n",
      "было (AUX): 35\n",
      "Клим (PROPN): 35\n",
      "да (PART): 34\n",
      "Эй (INTJ): 33\n",
      "дело (NOUN): 32\n",
      "Влас (NOUN): 32\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "\n",
    "doc1861 = nlp(book1861)\n",
    "tokens1 = [token.text for token in doc1861 if token.is_alpha and token.pos_ not in [\"ADP\", \"CONJ\", \"PART\", \"SCONJ\", \"ADV\", \"PRON\"] and token.text.isalpha() and len(token.text) > 1]\n",
    "\n",
    "doc1864 = nlp(book1864)\n",
    "tokens2 = [token.text for token in doc1864 if token.is_alpha and token.pos_ not in [\"ADP\", \"CONJ\", \"PART\", \"SCONJ\", \"ADV\", \"PRON\"] and token.text.isalpha() and len(token.text) > 1]\n",
    "\n",
    "doc1865 = nlp(book1865)\n",
    "tokens3 = [token.text for token in doc1865 if token.is_alpha and token.pos_ not in [\"ADP\", \"CONJ\", \"PART\", \"SCONJ\", \"ADV\", \"PRON\"] and token.text.isalpha() and len(token.text) > 1]\n",
    "\n",
    "doc1871 = nlp(book1871)\n",
    "tokens4 = [token.text for token in doc1871 if token.is_alpha and token.pos_ not in [\"ADP\", \"CONJ\", \"PART\", \"SCONJ\", \"ADV\", \"PRON\"] and token.text.isalpha() and len(token.text) > 1]\n",
    "\n",
    "doc1872 = nlp(book1872)\n",
    "tokens5 = [token.text for token in doc1872 if token.is_alpha and token.pos_ not in [\"ADP\", \"CONJ\", \"PART\", \"SCONJ\", \"ADV\", \"PRON\"] and token.text.isalpha() and len(token.text) > 1]\n",
    "\n",
    "doc1874 = nlp(book1874)\n",
    "tokens6 = [token.text for token in doc1874 if token.is_alpha and token.pos_ not in [\"ADP\", \"CONJ\", \"PART\", \"SCONJ\", \"ADV\", \"PRON\"] and token.text.isalpha() and len(token.text) > 1]\n",
    "\n",
    "# Подсчет частоты слов в каждом тексте\n",
    "word_freq1 = Counter(tokens1)\n",
    "word_freq2 = Counter(tokens2)\n",
    "word_freq3 = Counter(tokens3)\n",
    "word_freq4 = Counter(tokens4)\n",
    "word_freq5 = Counter(tokens5)\n",
    "word_freq6 = Counter(tokens6)\n",
    "\n",
    "print('Самые часто встречающиеся слова в тексте \"Крестьянкие дети\":')\n",
    "for word, freq in word_freq1.most_common(5):\n",
    "    token = nlp(word)[0]\n",
    "    pos_tag = token.pos_\n",
    "    print(f\"{word} ({pos_tag}): {freq}\")\n",
    "\n",
    "print('\\nСамые часто встречающиеся слова в тексте \"Мороз, Красный нос\":')\n",
    "for word, freq in word_freq2.most_common(5):\n",
    "    token = nlp(word)[0]\n",
    "    pos_tag = token.pos_\n",
    "    print(f\"{word} ({pos_tag}): {freq}\")\n",
    "\n",
    "print('\\nСамые часто встречающиеся слова в тексте \"Железная дорога\":')\n",
    "for word, freq in word_freq3.most_common(5):\n",
    "    token = nlp(word)[0]\n",
    "    pos_tag = token.pos_\n",
    "    print(f\"{word} ({pos_tag}): {freq}\")\n",
    "\n",
    "print('\\nСамые часто встречающиеся слова в тексте \"Дедушка Мазай и зайцы\":')\n",
    "for word, freq in word_freq4.most_common(5):\n",
    "    token = nlp(word)[0]\n",
    "    pos_tag = token.pos_\n",
    "    print(f\"{word} ({pos_tag}): {freq}\")\n",
    "\n",
    "print('\\nСамые часто встречающиеся слова в тексте \"Русские женщины\":')\n",
    "for word, freq in word_freq5.most_common(20):\n",
    "    token = nlp(word)[0]\n",
    "    pos_tag = token.pos_\n",
    "    print(f\"{word} ({pos_tag}): {freq}\")\n",
    "\n",
    "print('\\nСамые часто встречающиеся слова в тексте \"Кому на Руси жить хорошо\":')\n",
    "for word, freq in word_freq6.most_common(20):\n",
    "    token = nlp(word)[0]\n",
    "    pos_tag = token.pos_\n",
    "    print(f\"{word} ({pos_tag}): {freq}\")\n",
    "\n",
    "# ADJ: Прилагательное (Adjective)\n",
    "# ADP: Предлог (Adposition)\n",
    "# ADV: Наречие (Adverb)\n",
    "# AUX: Вспомогательный глагол (Auxiliary verb)\n",
    "# CONJ: Союз (Conjunction)\n",
    "# DET: Определитель (Determiner)\n",
    "# INTJ: Междометие (Interjection)\n",
    "# NOUN: Существительное (Noun)\n",
    "# NUM: Числительное (Numeral)\n",
    "# PART: Частица (Particle)\n",
    "# PRON: Местоимение (Pronoun)\n",
    "# PROPN: Имя собственное (Proper noun)\n",
    "# PUNCT: Пунктуация (Punctuation)\n",
    "# SCONJ: Подчинительный союз (Subordinating conjunction)\n",
    "# SYM: Символ (Symbol)\n",
    "# VERB: Глагол (Verb)\n",
    "# X: Другое (Other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод.\n",
    "\n",
    "**Для проведения морфологического анализа я взял творчество `Николая Алексеевича Некрасова` 1860-1870х годов. Взятые мной произведения Некрасова являются `стихотворениями и поэмами`.**\n",
    "\n",
    "**Первым делом я определил `лексическое разнообразие произведений`. Примечательно, что если брать произведения писателя в хронологическом порядке, то `наиболее` лексически разнообразными являются те, которые приходятся на промежуток времени с 1865-1871 годы (макс. значения: `0.72` и `0.76`).**\n",
    "\n",
    "**Можно предположить, что `самым красочным` из выбранных произведений Некрасова является \"Железная дорога\". Мое предположение следует из того, что именно в этом произведении писатель использует наибольшее количество уникальных прилагательных, где значение лексического разнообразия прилагательных равняется `0.235.`**\n",
    "\n",
    "**Также, я проанализировал какие слова чаще всего встречаются в выбранных произведениях. Очевидно, что самыми часто встречающимися словами будут являться союзы, наречия, частицы и т.п., так как они в большинстве своем являются связующими звеньями при составлении предложений. Поэтому я сделал дополнительную проверку, чтобы исключить ненужные мне для анализа слова. Из получившегося списка можно сделать вывод, что Некрасов часто упоминал слова, связанные с `окружающей средой`: \"Солнце\", \"Поле\", \"Дорога\". Помимо этого, можно отметить, что писатель не прочь был затронуть и `социальную среду`, так как часто всплывают слова как: \"Народ\", \"Крестьяне\", \"Странники\", \"Бог\", \"Люди\", \"Губернатор\", \"Княгиня\".**\n",
    "\n",
    "**Но в целом сложно сказать как менялось творчество писателя по мере его становления из выбранных мной произведений. Я смог использовать в своих целях только самые популярные, но они пришлись на зрелость писателя и на довольно короткий интервал из его творчества. Для лучшего анализа можно было бы взять произведения, написанные Некрасовым в более раннем возрасте, которые в свою очередь затрагивали бы другие времена, где могли бы подниматься другие темы и проблемы, но у меня не получилось их использовать для работы.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
