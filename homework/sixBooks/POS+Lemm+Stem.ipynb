{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Импорт библиотеки, загрузка моделей и словаря wordnet\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'started',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talking',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'doing']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Токенизация текста\n",
    "text = 'The way to get started is to quit talking and begin doing'\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('started', 'VBN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('quit', 'VB'),\n",
       " ('talking', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('begin', 'VB'),\n",
       " ('doing', 'VBG')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разбор по частям речи\n",
    "tagged = nltk.pos_tag(tokenized)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VB'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'started',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talking',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'doing']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизация\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "lemmatized = [lemm.lemmatize(word) for word in tokenized]\n",
    "lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', None),\n",
       " ('way', 'n'),\n",
       " ('to', None),\n",
       " ('get', 'v'),\n",
       " ('started', 'v'),\n",
       " ('is', 'v'),\n",
       " ('to', None),\n",
       " ('quit', 'v'),\n",
       " ('talking', 'v'),\n",
       " ('and', None),\n",
       " ('begin', 'v'),\n",
       " ('doing', 'v')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизация с учетом части речи\n",
    "# меняем теги\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'start',\n",
       " 'be',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talk',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'do']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизируем\n",
    "#tagged = [(word, pos_tagger(tag)) for word, tag in tagged]\n",
    "lemmatized = []\n",
    "for word, tag in tagged:\n",
    "    if tag == None:\n",
    "        lemmatized.append(lemm.lemmatize(word))\n",
    "    else:\n",
    "        lemmatized.append(lemm.lemmatize(word, tag))\n",
    "lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'start',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talk',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'do']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Стемминг English\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmed = [stemmer.stem(word) for word in tokenized]\n",
    "stemmed\n",
    "'The way to get started is to quit talking and begin doing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['у', 'лукомор', 'дуб', 'зелен', ',', 'злат', 'цеп', 'на', 'дуб', 'том']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Стемминг russian\n",
    "stemmer = SnowballStemmer(language='russian')\n",
    "text = 'У Лукоморья дуб зеленый, златая цепь на дубе том'\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "stemmed = [stemmer.stem(word) for word in tokenized]\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pymorphy\n",
    "https://pymorphy2.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Programming\\schoolx_python\\homework\\sixBooks\\POS+Lemm+Stem.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/schoolx_python/homework/sixBooks/POS%2BLemm%2BStem.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpymorphy2\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programming/schoolx_python/homework/sixBooks/POS%2BLemm%2BStem.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m morph \u001b[39m=\u001b[39m pymorphy2\u001b[39m.\u001b[39;49mMorphAnalyzer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/schoolx_python/homework/sixBooks/POS%2BLemm%2BStem.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m morph\u001b[39m.\u001b[39mparse(\u001b[39m'\u001b[39m\u001b[39mстали\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtag\u001b[39m.\u001b[39mPOS\n",
      "File \u001b[1;32mc:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_type_orig \u001b[39m=\u001b[39m result_type\n\u001b[0;32m    223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[1;32m--> 224\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_units(units)\n",
      "File \u001b[1;32mc:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[1;34m(self, units_unbound)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m item[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 235\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_unit(unit), \u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_unit(item[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), \u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[1;34m(self, unit)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_bound_unit\u001b[39m(\u001b[39mself\u001b[39m, unit):\n\u001b[1;32m--> 246\u001b[0m     unit \u001b[39m=\u001b[39m unit\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m    247\u001b[0m     unit\u001b[39m.\u001b[39minit(\u001b[39mself\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[39mreturn\u001b[39;00m unit\n",
      "File \u001b[1;32mc:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_params())\n",
      "File \u001b[1;32mc:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     74\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[1;32m---> 76\u001b[0m         (key, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, key, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_param_names()\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\velic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m:\n\u001b[0;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[1;32m---> 70\u001b[0m args, varargs, kw, default \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetargspec(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msorted\u001b[39m(args[\u001b[39m1\u001b[39m:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse('стали')[0].tag.POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='варкалось', tag=OpencorporaTag('NOUN,anim,masc sing,nomn'), normal_form='варкалось', score=0.5000531180282588, methods_stack=((DictionaryAnalyzer(), 'лось', 123, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'варка'))),\n",
       " Parse(word='варкалось', tag=OpencorporaTag('VERB,impf,intr neut,sing,past,indc'), normal_form='варкаться', score=0.4999468819717412, methods_stack=((FakeDictionary(), 'варкалось', 234, 9), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'алось')))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Варкалось что-то очень сильно и боялось появиться'\n",
    "morph.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
